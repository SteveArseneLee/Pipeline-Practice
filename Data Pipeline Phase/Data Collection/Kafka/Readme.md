# Kafka
<aside>
💡 대용량의 실시간 데이터 처리를 가능하게 하는 분산 스트리밍 플랫폼

### Components
1. Producer: 프로듀서는 데이터를 생성하고 Kafka에 전송하는 역할을 합니다. 예를 들어, 웹사이트의 로그 데이터를 Kafka로 보내는 경우, 웹사이트가 프로듀서가 됩니다. 프로듀서는 특정 Topic으로 데이터를 보내게 되며, 이 데이터는 Message라 불리는 단위로 전송됩니다.
2. Broker: 브로커는 Kafka 시스템의 핵심 구성 요소로써, 데이터를 저장하고 전송하는 역할을 합니다. Kafka 클러스터는 여러 대의 브로커 서버로 구성되며, 이들은 함께 데이터를 안정적으로 처리하게 돕습니다. 각 브로커는 하나 이상의 Topic 파티션을 가지며, 이는 병렬처리를 가능하게 해주고 높은 처리량을 가능하게 합니다.
3. Consumer: 컨슈머는 브로커로부터 데이터를 가져와서 처리하는 역할을 합니다. 프로듀서가 보낸 메시지를 브로커가 보관하고 있으며, 컨슈머는 필요할 때 이 메시지를 가져가서 사용합니다. 컨슈머는 특정 Topic으로부터 데이터를 가져와 처리하며, 여러 컨슈머가 하나의 컨슈머 그룹을 형성하여 병렬처리를 수행할 수 있습니다.
4. Topic: Kafka에서 메시지(데이터)는 Topic이라는 카테고리로 분류됩니다. 프로듀서는 특정 Topic으로 데이터를 보내고, 컨슈머는 특정 Topic으로부터 데이터를 가져옵니다. Topic은 하나 이상의 파티션으로 나눠집니다. 이는 데이터의 병렬처리를 가능하게 하며, 높은 처리량을 달성할 수 있습니다.
5. Partition: Kafka Topic은 하나 이상의 Partition으로 나눠집니다. Partition은 메시지를 순서대로 저장하는 구조로, 컨슈머가 데이터를 병렬로 처리할 수 있게 해줍니다. 즉, 각 컨슈머는 다른 파티션의 데이터를 독립적으로 처리할 수 있습니다. 또한, 파티션은 브로커에 분산 저장되므로, 데이터의 안정성을 보장합니다.


## Kafka와 연계된 기술들
### Kafka Streams
! 실시간 데이터 스트리밍 애플리케이션을 개발하는데 사용된다.
Kafka 클러스터에서 데이터 스트림을 처리하는 라이브러리로 데이터 스트림을 처리하고 변환하는 앱을 작성할 수 있다.
Kafka Streams는 실시간 데이터 파이프라인과 처리 애플리케이션을 만드는 데 필요한 기본적인 연산을 제공하는 클라이언트 라이브러리입니다. Kafka Streams를 사용하면, 실시간으로 데이터를 처리하고 집계하는 등의 복잡한 데이터 스트리밍 애플리케이션을 쉽게 개발할 수 있습니다.


**주요 기능**
1. Stream과 Table: Kafka Streams는 Stream과 Table이라는 두 가지 추상화를 제공합니다. Stream은 레코드의 무한 시퀀스를 의미하며, 각 레코드는 key, value, timestamp로 구성됩니다. Table은 key와 value 쌍의 집합으로, key에 대한 최신 value만 유지합니다. 이는 관계형 데이터베이스의 테이블 개념과 유사합니다.
2. Stateless and Stateful Operations: Kafka Streams는 상태를 유지하지 않는(stateless) 연산과 상태를 유지하는(stateful) 연산 모두를 지원합니다. Stateless 연산에는 map, filter, flatMap 등이 있으며, 이들은 각 레코드를 독립적으로 처리합니다. Stateful 연산에는 aggregation, join, windowing 등이 있으며, 이들은 하나 이상의 레코드를 기반으로 처리를 수행합니다.
3. Time Windowing: Kafka Streams는 윈도우 기반의 연산을 지원합니다. 이를 통해 특정 시간 범위에 속하는 레코드에 대한 처리를 수행할 수 있습니다. 예를 들어, 마지막 5분간의 데이터에 대한 평균을 계산하는 것이 가능합니다.
4. Integration with Kafka: Kafka Streams는 Kafka를 기반으로 동작하므로, Kafka의 높은 확장성, 내결함성, 및 실시간 처리 기능을 그대로 활용할 수 있습니다. 또한, Kafka Streams 애플리케이션은 일반적인 Kafka Producer와 Consumer처럼 동작하므로, 다른 Kafka 애플리케이션과의 호환성이 뛰어납니다.
5. Exactly-Once Processing Semantics: Kafka Streams는 메시지 처리에 있어서 '정확히 한 번'의 시맨틱을 지원합니다. 이는 메시지 손실이나 중복 처리 없이 메시지를 안전하게 처리할 수 있음을 보장합니다.