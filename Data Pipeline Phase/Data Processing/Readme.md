# Data Processing
데이터 처리는 수집된 데이터를 필요한 형태로 변환하고, 분석가능한 형태로 정리하는 과정입니다.  
이 과정은 데이터 정제, 데이터 변환, 데이터 집계, 데이터 분리 등을 포함할 수 있습니다.  
**수집된 데이터를 필요한 형태로 가공하고, 분석하기 적합한 형태로 만드는 단계**

---

### Skill Set
- Apache Spark: 대용량 데이터 처리를 위한 고성능 클러스터 컴퓨팅 시스템.
- Apache Beam: 배치 및 스트리밍 데이터 처리를 위한 프로그래밍 모델.
- Apache Flink: 스트림 처리와 배치 처리를 모두 지원하는 데이터 처리 엔진.
- Apache Hadoop: 대용량 데이터 처리를 위한 분산 처리 시스템.
- Apache Airflow: 복잡한 데이터 파이프라인을 구성하고 관리하는데 사용하는 플랫폼.
- Apache Samza: 스트림 처리를 위한 분산 시스템.
- Pandas: Python에서 사용하는 데이터 처리 및 분석 라이브러리.
- Dask: Python에서 대규모 데이터를 병렬로 처리하는 라이브러리.
- TensorFlow Transform(TF.Transform): TensorFlow로 대규모 데이터를 전처리하는 라이브러리.
- Luigi: 복잡한 배치 작업을 작성하고 관리하는 Python 라이브러리.