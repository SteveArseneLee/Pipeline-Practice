# Data Collection
다양한 소스에서 데이터를 수집합니다.  
이 소스는 웹 로그, 센서, 소셜 미디어 등 다양한 소스일 수 있습니다.  
이 소스는 웹 페이지, 소셜 미디어, 센서, 데이터베이스 등 다양할 수 있습니다.  
이 데이터는 원시 형태로 저장되며, 이후 필요에 따라 변환되거나 분석됩니다. 
**다양한 소스로부터 데이터를 수집하여 후속 처리 및 분석을 위한 준비를 하는 단계**  


---


### Skill Set
- Apache Kafka: 대규모 실시간 데이터 스트림 처리 및 메시징 시스템.
- Fluentd/Logstash: 로그 및 이벤트 데이터를 수집하고 처리하는 도구. 다양한 소스로부터 데이터를 수집하고, 변환하여 저장소로 전송합니다.
- Apache NiFi: 다양한 데이터 소스와 시스템 간의 데이터 흐름을 자동화하고 관리하는 플랫폼.
- Scrapy: 고성능 웹 크롤링 및 스크래핑 프레임워크. 웹사이트로부터 데이터를 추출하고 저장하는데 사용됩니다.
- Apache Sqoop: 관계형 데이터베이스와 Hadoop/HDFS 간의 대량 데이터 이동을 위한 도구.
- Filebeat: 경량 로그 파일 데이터 수집기, 주로 Elasticsearch와 함께 사용됩니다.
- Telegraf: 다양한 데이터 소스로부터 메트릭을 수집하는 에이전트.
- RabbitMQ/ActiveMQ: 메시지 브로커 시스템으로, 메시지 기반 데이터 수집 및 전달에 사용됩니다.
- CURL/HTTPie: 웹 API를 통한 데이터 수집에 유용한 커맨드 라인 도구.
- Promtail: 로그 파일에서 데이터를 수집하고 Loki로 전송.